{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt\n",
    "\n",
    "import av\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.exposure import rescale_intensity\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frames(video_path):\n",
    "    'Loads .avi video into array'\n",
    "    \n",
    "    frames = []\n",
    "    v = av.open(video_path)\n",
    "    for packet in v.demux():\n",
    "        for frame in packet.decode():\n",
    "            img = frame.to_image()\n",
    "            arr = np.asarray(img)\n",
    "            frames.append(arr)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_intensity(img):\n",
    "    p2, p98 = np.percentile(img, (0, 18))\n",
    "    return rescale_intensity(img, in_range=(p2,p98))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_threshold(im, thresholds):\n",
    "    'Thresholds RGB image by given RBG thresholds'\n",
    "    \n",
    "    c = im.copy()\n",
    "    mask = c[:,:,0] > thresholds[0][0]\n",
    "    for i, (l_thr, u_thr) in enumerate(thresholds):\n",
    "        mask &= (c[:,:,i] > l_thr)\n",
    "        mask &= (c[:,:,i] < u_thr)\n",
    "    c[~mask] = (0,0,0)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_grid(image_shape, distance):\n",
    "    'Creates an evenly spaced grid of coordinates across an image'\n",
    "    \n",
    "    indices = []\n",
    "    for xi in range(image_shape[0]):\n",
    "        for yi in range(image_shape[1]):\n",
    "            if (xi%distance, yi%distance)==(0,0): \n",
    "                indices.append((xi, yi))            \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbour_in_range(lower, upper, neighbour, _):\n",
    "    'Helper fn for region growing'\n",
    "    \n",
    "    return lower < neighbour < upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_region(seed, visited, im, lower_threshold, upper_threshold, fn=neighbour_in_range, HIGHEST_PIX_VALUE=255):\n",
    "    'Returns a region of pixel coordinate neighbours which satisfy the region criterion set by _fn_'\n",
    "\n",
    "    detected = set([seed])\n",
    "    region = set()\n",
    "\n",
    "    x_min = y_min = 0\n",
    "    x_max, y_max = im.shape\n",
    "    \n",
    "    while len(detected):\n",
    "        \n",
    "        pix = detected.pop()\n",
    "        \n",
    "        if pix in visited: continue\n",
    "                \n",
    "        pix_val = im[pix]\n",
    "        \n",
    "        x, y = pix\n",
    "    \n",
    "        for xi in range(max(x-1, x_min), min(x+2, x_max), 2):\n",
    "            if ((xi, y)) in visited: continue\n",
    "            if fn(lower_threshold, upper_threshold, im[xi, y], pix_val): detected.add((xi, y))\n",
    "        for yi in range(max(y-1, y_min), min(y+2, y_max), 2):\n",
    "            if ((x, yi)) in visited: continue\n",
    "            if fn(lower_threshold, upper_threshold, im[x, yi], pix_val): detected.add((x, yi))\n",
    "                \n",
    "        region.add(pix)\n",
    "        visited.add(pix)\n",
    "        \n",
    "    return list(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_regions(seeds, im, min_region_size, max_region_size, l_thr, u_thr, fn=neighbour_in_range):\n",
    "    'Runs collectRegion for every seed and returns a list of all connex regions in the image'\n",
    "    \n",
    "    regions = []\n",
    "    visited = set()\n",
    "\n",
    "    for seed in seeds:\n",
    "        \n",
    "        if seed in visited: continue\n",
    "            \n",
    "        region = collect_region(seed, visited, im, l_thr, u_thr, fn=fn)\n",
    "        \n",
    "        if min_region_size <= len(region) <= max_region_size: regions.append(region)\n",
    "        \n",
    "        \n",
    "    return np.array(regions), visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_indices(im, indices, exaggerate=False):\n",
    "    'Returns a copy of the image where indices are white'\n",
    "    'Exaggerate to ease visualization'\n",
    "    \n",
    "    tp = im.copy()\n",
    "    ind = np.array(indices)\n",
    "    x, y = ind[:,0], ind[:,1]\n",
    "    tp[x, y] = 255\n",
    "    \n",
    "    if exaggerate: \n",
    "        for i in range(-1,2):\n",
    "            for j in range(-1,2):\n",
    "                tp[x-i, y-j] = 255\n",
    "    return tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_binary(im):\n",
    "    c = im.copy()\n",
    "    grayscale = (rgb2gray(c)*256).astype('uint8')\n",
    "    grayscale[grayscale != 0] = 1\n",
    "    return grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_frame(region):\n",
    "    max_x = max(region[:,0])\n",
    "    max_y = max(region[:,1])\n",
    "    min_x = min(region[:,0])\n",
    "    min_y = min(region[:,1])\n",
    "    \n",
    "    return max_x, max_y, min_x, min_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bw_frame(im_shape, max_x, max_y, min_x, min_y):\n",
    "        \n",
    "    g = np.zeros(im_shape)\n",
    "    \n",
    "    g[max_x-3:max_x+3, min_y:max_y] = 255\n",
    "    g[min_x-3:min_x+3, min_y:max_y] = 255\n",
    "\n",
    "    g[min_x:max_x, min_y-3:min_y+3] = 255\n",
    "    g[min_x:max_x, max_y-3:max_y+3] = 255\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_to_color(im, color):\n",
    "    colors = {'red':0, 'green':1, 'blue':2}\n",
    "    assert (color in colors)\n",
    "    \n",
    "    c = colors[color]\n",
    "    \n",
    "    rgb_cell = [0,0,0]\n",
    "    rgb_cell[c] = 255\n",
    "    \n",
    "    frame = np.array([[[0,0,0] for _ in range(im.shape[1])] for _ in range(im.shape[0])])\n",
    "    \n",
    "    frame[im>0] = rgb_cell\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_rgb_regions(rgb_im, seed, min_size, max_size, l_thr, u_thr):\n",
    "    c = rgb_im.copy()\n",
    "    \n",
    "    black_white = rgb_to_binary(c)*255\n",
    "    seeds = create_index_grid(black_white.shape, seed)\n",
    "    regions, _ = collect_all_regions(seeds, black_white, min_size, max_size, l_thr, u_thr)\n",
    "    \n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_frames(underlying, overlying):\n",
    "    c = underlying.copy()\n",
    "    c[np.where(overlying)] = overlying[np.where(overlying)]\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidate_frame(im, max_x, max_y, min_x, min_y):\n",
    "    \n",
    "    x_limit, y_limit = im.shape[:-1]\n",
    "    \n",
    "    width = max(max_x-min_x, max_y-min_y)\n",
    "\n",
    "    x_delta = width - (max_x-min_x)\n",
    "    min_x -= x_delta//2\n",
    "    buffer = min(0, min_x)\n",
    "    \n",
    "    max_x += x_delta//2\n",
    "    'If border point'\n",
    "    if buffer: \n",
    "        max_x += (-buffer)\n",
    "        min_x = 0\n",
    "    else:\n",
    "        buffer = max_x - (x_limit-1)\n",
    "        if buffer > 0: \n",
    "            min_x -= buffer\n",
    "            max_x = x_limit-1\n",
    "    \n",
    "    y_delta = width - (max_y-min_y)\n",
    "    min_y -= y_delta//2\n",
    "    buffer = min(0, min_y)\n",
    "\n",
    "    max_y += y_delta//2\n",
    "    'If border point'\n",
    "    if buffer: \n",
    "        max_y += (-buffer)\n",
    "        min_y = 0\n",
    "    else:\n",
    "        buffer = max_y - (y_limit-1)\n",
    "        if buffer > 0: \n",
    "            min_y -= buffer\n",
    "            max_y = y_limit-1\n",
    "            \n",
    "    img = im.copy()\n",
    "    img = img[min_x:max_x, min_y:max_y]\n",
    "        \n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_colored_thumbnail(original_frame, candidate, candidate_validity):\n",
    "    \n",
    "    'Stretch the candidate'\n",
    "    c = Image.fromarray(candidate).resize((128, 128))\n",
    "    \n",
    "    'Make a white or red background depending on candidate validity'\n",
    "    if candidate_validity: \n",
    "        bg = np.array([[[255,255,255] for _ in range(128)] for _ in range(128)]).astype('uint8')\n",
    "    else: \n",
    "        bg = np.array([[[255,0,0] for _ in range(128)] for _ in range(128)]).astype('uint8')\n",
    "        \n",
    "    bg = Image.fromarray(bg)\n",
    "    \n",
    "    'Blend the candidate image and the colored background'\n",
    "    c = Image.blend(bg, c, alpha=0.5)\n",
    "    \n",
    "    'And apply it to the bottom right corner of the original frame'\n",
    "    frame = original_frame.copy()\n",
    "    frame[-128:, -128:] = c\n",
    "       \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_content(frame):\n",
    "\n",
    "    f = frame.copy()\n",
    "    max_x, max_y = f.shape[:-1]\n",
    "\n",
    "    x_0, y_0 = (max_x, max_y)\n",
    "\n",
    "    'Find content'\n",
    "    for xi in range(max_x):\n",
    "        for yi in range(max_y):\n",
    "            if (f[xi, yi] != np.array([255,255,255])).any():\n",
    "                x_0 = min(xi, x_0)\n",
    "                y_0 = min(yi, y_0)\n",
    "\n",
    "    x_1, y_1 = (x_0, y_0)\n",
    "    for xi in range(max_x-1, x_0, -1):\n",
    "        for yi in range(max_y-1, y_0, -1):\n",
    "            if (f[xi, yi] != np.array([255,255,255])).any():\n",
    "                x_1 = max(xi, x_1)\n",
    "                y_1 = max(yi, y_1)\n",
    "                \n",
    "    return f[x_0:x_1, y_0:y_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def periferal_pixels(im, width, threshold=0):\n",
    "\n",
    "    gray = rgb_to_binary(im)\n",
    "    max_x, max_y = gray.shape\n",
    "\n",
    "    perifery_pixels = sum(gray[0:width, 0:max_y].ravel()) + sum(gray[max_x-width:max_x, 0:max_y].ravel())\n",
    "    perifery_pixels += sum(gray[0:max_x, 0:width].ravel()) + sum(gray[0:max_x, max_y-width:max_y].ravel())\n",
    "    \n",
    "    return perifery_pixels > threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculator():\n",
    "    equation = ' '\n",
    "    s = ' '  \n",
    "    while s != '=':\n",
    "        s = yield s\n",
    "        equation += s  \n",
    "    yield eval(equation[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_equation(f):\n",
    "    mask = f.copy()\n",
    "    \n",
    "    max_y, max_x = mask.shape[:-1]\n",
    "    \n",
    "    mask[:,:,:] = [0,0,0]\n",
    "    mask[-64:, :-128, :] = [1, 1, 1] \n",
    "    \n",
    "    mask = Image.fromarray(mask)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    \n",
    "    offset = 5\n",
    "    font_size = 30\n",
    "    font = ImageFont.truetype('arial', font_size)\n",
    "    draw.text((offset, max_y-50),\"Equation: \",(255,255,255), font=font)\n",
    "    \n",
    "    offset += 0.6*font_size*8\n",
    "    \n",
    "    frame, validity, symbol = (mask.copy(), False, '')\n",
    "    \n",
    "    while True:\n",
    "        f = (yield frame)\n",
    "        v = (yield validity)\n",
    "        s = (yield symbol)        \n",
    "        if v:\n",
    "            draw.text((offset, max_y-50), s ,(255,255,255), font=font)\n",
    "            offset += 0.6*font_size*1.5\n",
    "        yield overlap_frames(f, np.array(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_frames(frames, path):\n",
    "    container = av.open(path, mode='w')\n",
    "    \n",
    "    stream = container.add_stream('mpeg4', rate=2)\n",
    "    (h, w) = frames[0].shape[:-1]\n",
    "\n",
    "    stream.width = w\n",
    "    stream.height = h\n",
    "    stream.pix_fmt = 'yuv420p'\n",
    "    \n",
    "    for f in frames:\n",
    "        frame = av.VideoFrame.from_ndarray(f, format='rgb24')\n",
    "        for packet in stream.encode(frame): container.mux(packet)\n",
    "    for packet in stream.encode(): container.mux(packet)\n",
    "    container.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Program flow__\n",
    "\n",
    " * Load .avi movie frames into `frames` array.\n",
    " * Equalize intensity of the `frames`, store in `eq_frames`.\n",
    " * Assume the vehicle does not cover any number or operator in the first frame. Use it as a reference.\n",
    " * Filter the equalized frames for __red__ objects. Find the single red object (the arrow) in every frame, using region growing.\n",
    " * Draw a rectangular frame around the arrow for visualization purposes.\n",
    " * For every subsequent frame in `eq_frames`:\n",
    "    * Fetch the area beneath the vehicle from the reference frame.\n",
    "    * Call this area a `candidate` - that is - a frame that might be sent to the Neural Net for classification if the following is __True__:\n",
    "       * It is not mostly white (avg pixel value > 254).\n",
    "       * It does not contain part of the arrow.\n",
    "       * It does not have any pixels set in its perifery (i.e. the entire region is encapsulated within the frame).\n",
    "       * It contains at most three regions of __either__ black or blue color. Frames containing multiple colors are rejected.\n",
    "    * Candidate is cropped and resized to 32x32 pixels if valid.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier():\n",
    "    'Mock classifier'\n",
    "    im = []\n",
    "    array = ['3', '3', '/', '2', '2', '+', '+', '+', '7', '*', '2', '2', '=']\n",
    "    for a in array:\n",
    "        im = (yield im)\n",
    "        yield a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(main) Loaded 42 frames\n",
      "(main) Equalizing frame intensities\n",
      "(main) Successfully evaluated all frames!   \n",
      "(main) Visualizing arrow path\n",
      "(main) Visualizing candidate frames\n",
      "(main) Visualizing equation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bitrate tolerance 128000 too small for bitrate 1024000, overriding\n"
     ]
    }
   ],
   "source": [
    "#def main():\n",
    "\n",
    "# Mock classifier\n",
    "clf = classifier()\n",
    "\n",
    "# Feed me. Yields result whed fed '='\n",
    "calc = calculator()\n",
    "next(calc)\n",
    "\n",
    "src_path = 'src/robot_parcours_1.avi'\n",
    "frames = load_frames(src_path)\n",
    "\n",
    "n = len(frames)\n",
    "print('(main) Loaded {} frames'.format(n))\n",
    "\n",
    "print('(main) Equalizing frame intensities')\n",
    "eq_frames = [equalize_intensity(f) for f in frames]\n",
    "\n",
    "# Use first frame as reference\n",
    "reference_frame = eq_frames[0]\n",
    "reference_region = set()\n",
    "\n",
    "# Threshold frames to find the _red_ arrow\n",
    "arrows = [rgb_threshold(f, ((180, 256), (-1,190), (-1,190))) for f in eq_frames]\n",
    "\n",
    "# Black images containing colored rectangle indicating positing of arrow\n",
    "arrow_rectangles = []\n",
    "\n",
    "# Extract from the reference image the area beneath vehicle for every frame\n",
    "candidates = []\n",
    "\n",
    "# Boolean: False if candidate is not qualified for classification\n",
    "candidate_validities = []\n",
    "\n",
    "# Helper variables for equation integrity purposes\n",
    "symbols = ' '\n",
    "active_equation = True\n",
    "\n",
    "\n",
    "for i, a in enumerate(arrows):\n",
    "    \n",
    "    print('(main) Interpreting frame {}'.format(i+1), end='\\r')\n",
    "    \n",
    "    # Do not consider anything for classification after a '=' has been registered\n",
    "    valid = active_equation\n",
    "    \n",
    "    # Symbol subject to change if a valid classification is made\n",
    "    symbol = 'N'\n",
    "    \n",
    "    # Locate the arrow in this frame\n",
    "    arrow_regions = locate_rgb_regions(a, 10, 1000, 3000, 250, 256)\n",
    "    assert (len(arrow_regions)==1), 'Found no arrow in frame {}'.format(i)\n",
    "    \n",
    "    # Draw surrounding rectangle\n",
    "    max_x, max_y, min_x, min_y = locate_frame(arrow_regions[0])\n",
    "    frame = draw_bw_frame(a.shape[:-1], max_x, max_y, min_x, min_y)\n",
    "    arrow_rectangles.append(gray_to_color(frame, 'green'))\n",
    "\n",
    "    # Discard candidate if it contains part of the arrow\n",
    "    if i == 0: reference_region = set([tuple(a) for a in arrow_regions[0]])\n",
    "    valid &= len(set([tuple(a) for a in arrow_regions[0]])&reference_region)==0\n",
    "        \n",
    "    # Extract candidate frame of area beneath vehicle\n",
    "    candidate = extract_candidate_frame(reference_frame, max_x, max_y, min_x, min_y)\n",
    "    \n",
    "    # Discard candidate if mostly empty\n",
    "    if valid: \n",
    "        valid = sum(candidate.ravel()) / len(candidate.ravel())<254\n",
    "        \n",
    "        # Discard candidate if there exist objects on the border\n",
    "        if valid: \n",
    "            valid = not periferal_pixels(candidate, 5)\n",
    "            # 'Candidate invalid if it contains more than three objects (division operator)'\n",
    "            #if valid:\n",
    "            #    black_content = rgb_threshold(candidate, ((-1, 256), (-1, 256), (-1, 120)))\n",
    "            #    black_objects = len(locate_rgb_regions(black_content, 2, 10, 1000, 2, 256))\n",
    "            #    \n",
    "            #    blue_content = rgb_threshold(candidate, ((-1, 120), (-1, 200), (120, 256)))\n",
    "            #    blue_objects = len(locate_rgb_regions(blue_content, 2, 10, 1000, 2, 256))\n",
    "            #    \n",
    "            #    valid = ( (blue_objects in (1,2,3) and black_objects == 0) or\n",
    "            #              (blue_objects == 0 and black_objects in (1,2,3))\n",
    "            #            )\n",
    "            #    print('pic {} validity: {}. Found {} black objects and {} blue objects'.format(i, valid, black_objects, blue_objects))\n",
    "\n",
    "            # 'If found'\n",
    "    \n",
    "            if valid:\n",
    "\n",
    "                valid = False\n",
    "                # 'Tight crop to ease classification'\n",
    "                candidate = crop_content(candidate)\n",
    "                candidate = np.array(Image.fromarray(candidate).resize((32,32)))        \n",
    "\n",
    "                # 'Fetch symbol from classifier'\n",
    "                next(clf)\n",
    "                symbol = clf.send(candidate)\n",
    "\n",
    "                # 'Do not accept two identical symbols who are not separated by at least one invalid frame'\n",
    "                if not symbol==symbols[-1]:\n",
    "\n",
    "                    valid = True\n",
    "\n",
    "                    # 'Send validated symbol to calculator'\n",
    "                    result = calc.send(symbol)\n",
    "\n",
    "                    # print('{} added to equation'.format(symbol))\n",
    "                    if symbol == '=': active_equation = False\n",
    "    \n",
    "    # Candidate is not valid, and is resized - uncropped.      \n",
    "    if not valid: candidate = np.array(Image.fromarray(candidate).resize((32,32)))    \n",
    "    \n",
    "    symbols += symbol\n",
    "    \n",
    "    # For visualization purposes\n",
    "    candidates.append(candidate)\n",
    "    candidate_validities.append(valid)\n",
    "    \n",
    "    \n",
    "print('(main) Successfully evaluated all frames!   ')\n",
    "print('(main) Visualizing arrow path')\n",
    "# 'Add the surrounding rectangles to the original footage'\n",
    "original_and_arrow_trace = [overlap_frames(f, a) for f, a in zip(frames, arrow_rectangles)]\n",
    "\n",
    "print('(main) Visualizing candidate frames')\n",
    "# 'Add colored thumbnail of candidate'\n",
    "with_thumbnail = [add_colored_thumbnail(f, c, v) for f, c, v in zip(original_and_arrow_trace, candidates, candidate_validities)]\n",
    "\n",
    "with_equation = []\n",
    "viz = visualize_equation(reference_frame)\n",
    "\n",
    "print('(main) Visualizing equation')\n",
    "for f, v, s in zip(with_thumbnail, candidate_validities, symbols[1:]):\n",
    "    next(viz)\n",
    "    viz.send(f), viz.send(v)\n",
    "    frame = viz.send(s)\n",
    "    if s == '=':\n",
    "        next(viz)\n",
    "        viz.send(frame), viz.send(True)\n",
    "        frame = viz.send(str(result))\n",
    "    with_equation.append(frame)     \n",
    "\n",
    "# 'Output'\n",
    "output_frames(with_equation, 'out/test_equation.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (c, v) in enumerate(zip(candidates, candidate_validities)):\n",
    "    if v:\n",
    "        c = Image.fromarray(c)\n",
    "        c.save('out/candidates/im{}.png'.format(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
