{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt\n",
    "\n",
    "import av\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.exposure import rescale_intensity\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frames(video_path):\n",
    "    'Loads .avi video into array'\n",
    "    \n",
    "    frames = []\n",
    "    v = av.open(video_path)\n",
    "    for packet in v.demux():\n",
    "        for frame in packet.decode():\n",
    "            img = frame.to_image()\n",
    "            arr = np.asarray(img)\n",
    "            frames.append(arr)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_intensity(img):\n",
    "    p2, p98 = np.percentile(img, (0, 18))\n",
    "    return rescale_intensity(img, in_range=(p2,p98))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_threshold(im, thresholds):\n",
    "    'Thresholds RGB image by given RBG thresholds'\n",
    "    \n",
    "    c = im.copy()\n",
    "    mask = c[:,:,0] > thresholds[0][0]\n",
    "    for i, (l_thr, u_thr) in enumerate(thresholds):\n",
    "        mask &= (c[:,:,i] > l_thr)\n",
    "        mask &= (c[:,:,i] < u_thr)\n",
    "    c[~mask] = (0,0,0)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_grid(image_shape, distance):\n",
    "    'Creates an evenly spaced grid of coordinates across an image'\n",
    "               \n",
    "    return [(x, y) for x in range(0, image_shape[0], distance) for y in range(0, image_shape[1], distance)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_region(seed, visited, im, lower_threshold, upper_threshold):\n",
    "    'Returns a region of pixel coordinate neighbours withing thresholds'\n",
    "\n",
    "    detected = set([seed])\n",
    "    region = set()\n",
    "\n",
    "    x_min = y_min = 0\n",
    "    x_max, y_max = im.shape\n",
    "    \n",
    "    while len(detected):\n",
    "        \n",
    "        pix = detected.pop()\n",
    "        \n",
    "        if pix in visited: continue\n",
    "                \n",
    "        x, y = pix\n",
    "    \n",
    "        for xi in range(max(x-1, x_min), min(x+2, x_max), 2):\n",
    "            if ((xi, y)) in visited: continue\n",
    "            if (lower_threshold < im[xi, y] < upper_threshold): detected.add((xi, y))\n",
    "        for yi in range(max(y-1, y_min), min(y+2, y_max), 2):\n",
    "            if ((x, yi)) in visited: continue\n",
    "            if (lower_threshold < im[x, yi] < upper_threshold): detected.add((x, yi))\n",
    "                \n",
    "        region.add(pix)\n",
    "        visited.add(pix)\n",
    "        \n",
    "    return list(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_regions(seeds, im, min_region_size, max_region_size, l_thr, u_thr):\n",
    "    'Runs collectRegion for every seed and returns a list of all connex regions in the image'\n",
    "    \n",
    "    regions = []\n",
    "    visited = set()\n",
    "\n",
    "    for seed in seeds:\n",
    "        \n",
    "        if seed in visited: continue\n",
    "            \n",
    "        region = collect_region(seed, visited, im, l_thr, u_thr)\n",
    "        \n",
    "        if min_region_size <= len(region) <= max_region_size: regions.append(region)\n",
    "        \n",
    "    return np.array(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_binary(im):\n",
    "    c = im.copy()\n",
    "    grayscale = (rgb2gray(c)*256).astype('uint8')\n",
    "    grayscale[grayscale != 0] = 1\n",
    "    return grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_frame(region):\n",
    "    max_x = max(region[:,0])\n",
    "    max_y = max(region[:,1])\n",
    "    min_x = min(region[:,0])\n",
    "    min_y = min(region[:,1])\n",
    "    \n",
    "    return max_x, max_y, min_x, min_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bw_rectangle(im_shape, max_x, max_y, min_x, min_y):\n",
    "        \n",
    "    g = np.zeros(im_shape)\n",
    "    \n",
    "    g[max_x-3:max_x+3, min_y:max_y] = 255\n",
    "    g[min_x-3:min_x+3, min_y:max_y] = 255\n",
    "\n",
    "    g[min_x:max_x, min_y-3:min_y+3] = 255\n",
    "    g[min_x:max_x, max_y-3:max_y+3] = 255\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_to_color(gray_frame, color):\n",
    "    COLORS = {'red':0, 'green':1, 'blue':2}\n",
    "    assert (color in COLORS)\n",
    "    \n",
    "    c = COLORS[color]\n",
    "    rgb_cell = [0,0,0]\n",
    "    rgb_cell[c] = 255\n",
    "    \n",
    "    new_shape = (gray_frame.shape[0], gray_frame.shape[1], 3)\n",
    "    rgb_frame = np.zeros(new_shape).astype('uint8')  \n",
    "    \n",
    "    rgb_frame[np.where(gray_frame!=0)] = rgb_cell\n",
    "    \n",
    "    return rgb_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_rgb_regions(rgb_im, seed, min_size, max_size, l_thr, u_thr):\n",
    "    c = rgb_im.copy()\n",
    "    black_white = rgb_to_binary(c)*255\n",
    "    seeds = create_index_grid(black_white.shape, seed)\n",
    "    regions = collect_all_regions(seeds, black_white, min_size, max_size, l_thr, u_thr)\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_frames(underlying, overlying):\n",
    "    c = underlying.copy()\n",
    "    c[np.where(overlying)] = overlying[np.where(overlying)]\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidate_frame(im, max_x, max_y, min_x, min_y):\n",
    "    \n",
    "    x_limit, y_limit = im.shape[:-1]\n",
    "    \n",
    "    width = max(max_x-min_x, max_y-min_y)\n",
    "\n",
    "    x_delta = width - (max_x-min_x)\n",
    "    min_x -= x_delta//2\n",
    "    buffer = min(0, min_x)\n",
    "    \n",
    "    max_x += x_delta//2\n",
    "    'If border point'\n",
    "    if buffer: \n",
    "        max_x += (-buffer)\n",
    "        min_x = 0\n",
    "    else:\n",
    "        buffer = max_x - (x_limit-1)\n",
    "        if buffer > 0: \n",
    "            min_x -= buffer\n",
    "            max_x = x_limit-1\n",
    "    \n",
    "    y_delta = width - (max_y-min_y)\n",
    "    min_y -= y_delta//2\n",
    "    buffer = min(0, min_y)\n",
    "\n",
    "    max_y += y_delta//2\n",
    "    'If border point'\n",
    "    if buffer: \n",
    "        max_y += (-buffer)\n",
    "        min_y = 0\n",
    "    else:\n",
    "        buffer = max_y - (y_limit-1)\n",
    "        if buffer > 0: \n",
    "            min_y -= buffer\n",
    "            max_y = y_limit-1\n",
    "            \n",
    "    img = im.copy()\n",
    "    img = img[min_x:max_x, min_y:max_y]\n",
    "        \n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_colored_thumbnail(original_frame, candidate, candidate_validity):\n",
    "    \n",
    "    'Stretch the candidate'\n",
    "    c = Image.fromarray(candidate).resize((128, 128))\n",
    "    \n",
    "    'Make a white or red background depending on candidate validity'\n",
    "    if candidate_validity: \n",
    "        bg = np.array([[[255,255,255] for _ in range(128)] for _ in range(128)]).astype('uint8')\n",
    "    else: \n",
    "        bg = np.array([[[255,0,0] for _ in range(128)] for _ in range(128)]).astype('uint8')\n",
    "        \n",
    "    bg = Image.fromarray(bg)\n",
    "    \n",
    "    'Blend the candidate image and the colored background'\n",
    "    c = Image.blend(bg, c, alpha=0.5)\n",
    "    \n",
    "    'And apply it to the bottom right corner of the original frame'\n",
    "    frame = original_frame.copy()\n",
    "    frame[-128:, -128:] = c\n",
    "       \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_content(frame):\n",
    "\n",
    "    f = frame.copy()\n",
    "    max_x, max_y = f.shape[:-1]\n",
    "\n",
    "    x_0, y_0 = (max_x, max_y)\n",
    "\n",
    "    'Find content'\n",
    "    for xi in range(max_x):\n",
    "        for yi in range(max_y):\n",
    "            if (f[xi, yi] != np.array([255,255,255])).any():\n",
    "                x_0 = min(xi, x_0)\n",
    "                y_0 = min(yi, y_0)\n",
    "\n",
    "    x_1, y_1 = (x_0, y_0)\n",
    "    for xi in range(max_x-1, x_0, -1):\n",
    "        for yi in range(max_y-1, y_0, -1):\n",
    "            if (f[xi, yi] != np.array([255,255,255])).any():\n",
    "                x_1 = max(xi, x_1)\n",
    "                y_1 = max(yi, y_1)\n",
    "                \n",
    "    return f[x_0:x_1, y_0:y_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def periferal_pixels(im, width, threshold=0):\n",
    "\n",
    "    gray = rgb_to_binary(im)\n",
    "    max_x, max_y = gray.shape\n",
    "\n",
    "    perifery_pixels = sum(gray[0:width, 0:max_y].ravel()) + sum(gray[max_x-width:max_x, 0:max_y].ravel())\n",
    "    perifery_pixels += sum(gray[0:max_x, 0:width].ravel()) + sum(gray[0:max_x, max_y-width:max_y].ravel())\n",
    "    \n",
    "    return perifery_pixels > threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculator():\n",
    "    equation = ' '\n",
    "    s = ' '  \n",
    "    while s != '=':\n",
    "        s = yield s\n",
    "        equation += s  \n",
    "    yield eval(equation[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_equation(shape):\n",
    "    mask = np.zeros(shape).astype('uint8')\n",
    "    \n",
    "    max_y, max_x = mask.shape[:-1]\n",
    "    \n",
    "    mask[-64:, :-128, :] = [1, 1, 1] \n",
    "    \n",
    "    mask = Image.fromarray(mask)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    \n",
    "    offset = 5\n",
    "    font_size = 30\n",
    "    font = ImageFont.truetype('arial', font_size)\n",
    "    draw.text((offset, max_y-50),\"Equation: \",(255,255,255), font=font)\n",
    "    \n",
    "    offset += 0.6*font_size*8\n",
    "    \n",
    "    frame, validity, symbol = (mask.copy(), False, '')\n",
    "    \n",
    "    while True:\n",
    "        f = (yield frame)\n",
    "        v = (yield validity)\n",
    "        s = (yield symbol)        \n",
    "        if v:\n",
    "            draw.text((offset, max_y-50), s ,(255,255,255), font=font)\n",
    "            offset += 0.6*font_size*1.5\n",
    "        yield overlap_frames(f, np.array(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poke_visualizer(viz, im, symbol, valid, result):\n",
    "    \n",
    "    next(viz)\n",
    "    viz.send(im), viz.send(valid)\n",
    "    frame = viz.send(symbol)\n",
    "    if symbol == '=':\n",
    "        next(viz)\n",
    "        viz.send(im), viz.send(True)\n",
    "        frame = viz.send(str(result))\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_video(frames, path):\n",
    "    container = av.open(path, mode='w')\n",
    "    \n",
    "    stream = container.add_stream('mpeg4', rate=2)\n",
    "    (h, w) = frames[0].shape[:-1]\n",
    "\n",
    "    stream.width = w\n",
    "    stream.height = h\n",
    "    stream.pix_fmt = 'yuv420p'\n",
    "    \n",
    "    for f in frames:\n",
    "        frame = av.VideoFrame.from_ndarray(f, format='rgb24')\n",
    "        for packet in stream.encode(frame): container.mux(packet)\n",
    "    for packet in stream.encode(): container.mux(packet)\n",
    "    container.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Program flow__\n",
    "\n",
    " * Load .avi movie frames into `frames` array.\n",
    " * Equalize intensity of the `frames`, store in `eq_frames`.\n",
    " * Assume the vehicle does not cover any number or operator in the first frame. Use it as a reference.\n",
    " * Filter the equalized frames for __red__ objects. Find the single red object (the arrow) in every frame, using region growing.\n",
    " * Draw a rectangular frame around the arrow for visualization purposes.\n",
    " * For every subsequent frame in `eq_frames`:\n",
    "    * Fetch the area beneath the vehicle from the reference frame.\n",
    "    * Call this area a `candidate` - that is - a frame that might be sent to the Neural Net for classification if the following is __True__:\n",
    "       * It is not mostly white (avg pixel value > 254).\n",
    "       * It does not contain part of the arrow.\n",
    "       * It does not have any pixels set in its perifery (i.e. the entire region is encapsulated within the frame).\n",
    "       * It contains at most three regions of __either__ black or blue color. Frames containing multiple colors are rejected.\n",
    "    * Candidate is cropped and resized to 32x32 pixels if valid.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier():\n",
    "    'Mock classifier'\n",
    "    im = []\n",
    "    array = ['3', '3', '/', '2', '2', '+', '+', '+', '7', '*', '2', '2', '=']\n",
    "    for a in array:\n",
    "        im = (yield im)\n",
    "        yield a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    src_path = 'src/robot_parcours_1.avi'\n",
    "    frames = load_frames(src_path)\n",
    "\n",
    "    n = len(frames)\n",
    "    print('(main) Loaded {} frames'.format(n))\n",
    "\n",
    "    # Mock classifier\n",
    "    clf = classifier()\n",
    "\n",
    "    # Feed me. Yields result whed fed '='\n",
    "    calc = calculator()\n",
    "    next(calc)\n",
    "\n",
    "    # Keeps track of the equation visualization state\n",
    "    viz = visualize_equation(frames[0].shape)\n",
    "\n",
    "    # Helper variables for equation integrity purposes\n",
    "    result = 0\n",
    "    symbols = ' '\n",
    "    active_equation = True\n",
    "\n",
    "    # For video output\n",
    "    output_frames = []\n",
    "\n",
    "    print('   Frame\\t   Valid\\t   Prepared\\t   Time  \\t ')\n",
    "    print('+---------------------------------------------------------------+')\n",
    "\n",
    "    for i, f in enumerate(frames):\n",
    "        \n",
    "        tic = time()\n",
    "        print('   {}'.format(i+1), end='\\t\\t')\n",
    "        \n",
    "        # Do not consider anything for classification after a '=' has been registered\n",
    "        valid = active_equation\n",
    "\n",
    "        # Symbol subject to change if a valid classification is made\n",
    "        symbol = 'N'\n",
    "\n",
    "        # Equalize intensity and filter the (red) arrow\n",
    "        eqf = equalize_intensity(f)\n",
    "        arrow = rgb_threshold(eqf, ((180, 256), (-1,190), (-1,190)))\n",
    "\n",
    "        # Locate arrow indices using region growing\n",
    "        arrow_regions = locate_rgb_regions(arrow, 15, 1000, 3000, 250, 256)\n",
    "        assert (len(arrow_regions)==1), 'Found no arrow in frame {}'.format(i)\n",
    "\n",
    "        # Draw surrounding rectangle\n",
    "        max_x, max_y, min_x, min_y = locate_frame(arrow_regions[0])\n",
    "        bw_rectangle = draw_bw_rectangle(arrow.shape[:-1], max_x, max_y, min_x, min_y)\n",
    "        rgb_rectangle = gray_to_color(bw_rectangle, 'green')\n",
    "\n",
    "        # Assume all symbols are visible in first frame\n",
    "        # Use this as a reference\n",
    "        if i == 0: \n",
    "            reference_region = set([tuple(a) for a in arrow_regions[0]])\n",
    "            reference_frame = eqf\n",
    "\n",
    "        # Extract candidate from reference frame, \n",
    "        # corresponding to the area beneath vehicle in this frame\n",
    "        candidate = extract_candidate_frame(reference_frame, max_x, max_y, min_x, min_y)\n",
    "\n",
    "        # Discard candidate if there exist objects on the border\n",
    "        valid = not periferal_pixels(candidate, 5)\n",
    "        \n",
    "        if valid: \n",
    "            # Discard candidate if mostly empty\n",
    "            valid = sum(candidate.ravel()) / len(candidate.ravel())<254\n",
    "\n",
    "            if valid: \n",
    "                # A frame is not fit for classification if it contains part of the arrow\n",
    "                valid = len(set([tuple(a) for a in arrow_regions[0]])&reference_region)==0\n",
    "                \n",
    "                if valid:\n",
    "                    # Crop to ease classification, resize to 32x32\n",
    "                    candidate = crop_content(candidate)\n",
    "                    candidate = np.array(Image.fromarray(candidate).resize((32,32)))        \n",
    "\n",
    "                    # MOCK CLASSIFIER #\n",
    "\n",
    "                    next(clf)\n",
    "                    symbol = clf.send(candidate)\n",
    "\n",
    "                    # MOCK CLASSIFIER #\n",
    "\n",
    "\n",
    "                    # Render candidate invalid if two frames _in a row_ yield the same symbol\n",
    "                    if symbol == symbols[-1]: valid = False\n",
    "                    else:\n",
    "                        # Send valid symbol to calculator\n",
    "                        result = calc.send(symbol)\n",
    "                        # = terminates the equation and implies no need for further classification\n",
    "                        active_equation = (symbol != '=')\n",
    "\n",
    "        symbols += symbol\n",
    "        print('   {}  '.format(valid), end='\\t')\n",
    "\n",
    "        ## PREPARE OUTPUT FRAME ##\n",
    "        with_arrow_rect = overlap_frames(f, rgb_rectangle)\n",
    "        print('   .', end=' ')\n",
    "        with_thumbnail = add_colored_thumbnail(with_arrow_rect, candidate, valid)\n",
    "        print('.', end=' ')\n",
    "        with_equation = poke_visualizer(viz, with_thumbnail, symbol, valid, result)\n",
    "        print('.', end=' ')\n",
    "        output_frames.append(with_equation)\n",
    "        print('.', end='\\t')\n",
    "        toc = time()    \n",
    "        print(f'    {toc-tic:.2f}')\n",
    "\n",
    "    make_video(output_frames, 'out/effective.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(main) Loaded 42 frames\n",
      "   Frame\t   Valid\t   Prepared\t   Time  \t \n",
      "+---------------------------------------------------------------+\n",
      "   1\t\t   False  \t   . . . .\t    0.21\n",
      "   2\t\t   False  \t   . . . .\t    0.20\n",
      "   3\t\t   False  \t   . . . .\t    0.20\n",
      "   4\t\t   False  \t   . . . .\t    0.21\n",
      "   5\t\t   False  \t   . . . .\t    0.20\n",
      "   6\t\t   False  \t   . . . .\t    0.20\n",
      "   7\t\t   False  \t   . . . .\t    0.22\n",
      "   8\t\t   False  \t   . . . .\t    0.24\n",
      "   9\t\t   True  \t   . . . .\t    0.23\n",
      "   10\t\t   False  \t   . . . .\t    0.25\n",
      "   11\t\t   False  \t   . . . .\t    0.19\n",
      "   12\t\t   False  \t   . . . .\t    0.19\n",
      "   13\t\t   True  \t   . . . .\t    0.25\n",
      "   14\t\t   False  \t   . . . .\t    0.19\n",
      "   15\t\t   False  \t   . . . .\t    0.22\n",
      "   16\t\t   False  \t   . . . .\t    0.19\n",
      "   17\t\t   False  \t   . . . .\t    0.19\n",
      "   18\t\t   True  \t   . . . .\t    0.24\n",
      "   19\t\t   False  \t   . . . .\t    0.24\n",
      "   20\t\t   False  \t   . . . .\t    0.21\n",
      "   21\t\t   True  \t   . . . .\t    0.32\n",
      "   22\t\t   False  \t   . . . .\t    0.26\n",
      "   23\t\t   False  \t   . . . .\t    0.24\n",
      "   24\t\t   False  \t   . . . .\t    0.20\n",
      "   25\t\t   False  \t   . . . .\t    0.20\n",
      "   26\t\t   False  \t   . . . .\t    0.22\n",
      "   27\t\t   False  \t   . . . .\t    0.19\n",
      "   28\t\t   True  \t   . . . .\t    0.24\n",
      "   29\t\t   False  \t   . . . .\t    0.19\n",
      "   30\t\t   True  \t   . . . .\t    0.24\n",
      "   31\t\t   False  \t   . . . .\t    0.21\n",
      "   32\t\t   False  \t   . . . .\t    0.20\n",
      "   33\t\t   True  \t   . . . .\t    0.32\n",
      "   34\t\t   False  \t   . . . .\t    0.26\n",
      "   35\t\t   False  \t   . . . .\t    0.24\n",
      "   36\t\t   False  \t   . . . .\t    0.22\n",
      "   37\t\t   True  \t   . . . .\t    0.28\n",
      "   38\t\t   False  \t   . . . .\t    0.20\n",
      "   39\t\t   False  \t   . . . .\t    0.19\n",
      "   40\t\t   False  \t   . . . .\t    0.19\n",
      "   41\t\t   False  \t   . . . .\t    0.20\n",
      "   42\t\t   False  \t   . . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bitrate tolerance 128000 too small for bitrate 1024000, overriding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". .\t    0.21\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "main()\n",
    "toc = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.866992950439453"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toc-tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
